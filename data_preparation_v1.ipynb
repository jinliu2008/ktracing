{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"boolean\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"boolean\"\n",
    "}\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "import feather\n",
    "from embedder.regression import Embedder\n",
    "from embedder.preprocessing import (categorize,\n",
    "     pick_emb_dim,  get_embed_df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import column_or_1d\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(token=r\"C:\\Users\\meipaopao\\PycharmProjects\\ktracing_gcs.json\")\n",
    "\n",
    "def save_to_feather(file_name=\"validation-v0-00000000000\", output_file_name=\"validation_v0\", max_=30):\n",
    "    dataset = pd.DataFrame()\n",
    "    for i in range(max_):\n",
    "        file_path = f'gs://ktracing/{file_name}{i}.csv'\n",
    "        if not fs.exists(file_path):\n",
    "            break\n",
    "        with fs.open(file_path) as f:\n",
    "            print(i)\n",
    "            df = pd.read_csv(f, dtype=dtypes, index_col=False)\n",
    "            print('current shape:', df.shape)\n",
    "            dataset = pd.concat([dataset, df])\n",
    "            print('updated shape:', dataset.shape)\n",
    "    print('overall shape:', dataset.shape)\n",
    "    dataset.reset_index(drop=True).to_feather(f'{output_file_name}.feather')\n",
    "    \n",
    "# gs://ktracing/train-v0-000000000000.csv\n",
    "# https://storage.cloud.google.com/ktracing/train_sample_000000000000.csv?authuser=1\n",
    "#save_to_feather(file_name=\"train-v0-00000000000\", output_file_name=\"train_v0\")\n",
    "#save_to_feather(file_name=\"train_sample_00000000000\", output_file_name=\"train_sample_v0\")\n",
    "# gs://ktracing/train_sample_v0_000000000000.csv\n",
    "#save_to_feather(file_name=\"train_sample_v0_00000000000\", output_file_name=\"train_sample_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:33<00:00, 29.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 2266489\n",
      "Wall time: 37.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm as tqdm_notebook\n",
    "seq_len = 100\n",
    "# generate train sample indices\n",
    "def get_sample_indices(df_):\n",
    "    df = df_[df_.content_type_id==False]\n",
    "    df.set_index('row_id', inplace=True)\n",
    "    sample_indices = []\n",
    "    user_indices = []\n",
    "    df_users = df.groupby('user_id').groups\n",
    "    for user_idx, start_indices in enumerate(tqdm_notebook(df_users.values())):\n",
    "        for num, curr_index in enumerate(start_indices):\n",
    "            selected_index = start_indices[:num+1]\n",
    "            if len(selected_index)>seq_len:\n",
    "                selected_index = selected_index[-seq_len:]\n",
    "            sample_indices.append(selected_index)\n",
    "            user_indices.append(user_idx)\n",
    "    return sample_indices, user_indices\n",
    "\n",
    "# data load\n",
    "print('loading data')\n",
    "train_df_ = feather.read_dataframe('train_sample_v0.feather')\n",
    "train_df_.sort_values(['user_id','timestamp'],inplace=True)\n",
    "#test_df = feather.read_dataframe('validation_v0.feather')\n",
    "train_samples, train_users = get_sample_indices(train_df_)\n",
    "print('size:', len(train_samples))\n",
    "#print(train_df_.head())\n",
    "# df_row = train_df_.set_index('row_id')\n",
    "#print('reset index:\\n', df_row.head())\n",
    "# for i, index in enumerate(train_samples):\n",
    "#     print('curr user:',train_users[i] )\n",
    "#     print(len(df_row.loc[index].values))\n",
    "# train_df_ = feather.read_dataframe('train_sample_v1.feather')\n",
    "# train_df_.sort_values(['user_id','timestamp'],inplace=True)\n",
    "\n",
    "# train_df_['row_id'] = train_df_['row_id'].astype(int)\n",
    "# df_row = train_df_.copy()\n",
    "# df_row.set_index('row_id',inplace=True, drop=True)\n",
    "# #print(df_row)\n",
    "# print(df_row.shape)\n",
    "# a=df_row.index.tolist()\n",
    "# print(a[100:500])\n",
    "# df_row.loc[[24171]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (2306848, 10)\n",
      "head:     row_id    timestamp  user_id  content_id  content_type_id  \\\n",
      "0   125339            0  2659874        5851            False   \n",
      "1   125340        26987  2659874        2159            False   \n",
      "2   125341        65153  2659874        5085            False   \n",
      "3   125342        91700  2659874        3407            False   \n",
      "4   125343       200660  2659874        5856            False   \n",
      "..     ...          ...      ...         ...              ...   \n",
      "95  125434  24249110614  2659874        6109            False   \n",
      "96  125435  24249186111  2659874        8925            False   \n",
      "97  125436  24249278290  2659874         695            False   \n",
      "98  125437  24249347107  2659874         700            False   \n",
      "99  125438  24249421456  2659874        5493            False   \n",
      "\n",
      "    task_container_id  user_answer  answered_correctly  \\\n",
      "0                   0            1                   0   \n",
      "1                   1            3                   1   \n",
      "2                   2            1                   0   \n",
      "3                   3            3                   1   \n",
      "4                   4            3                   0   \n",
      "..                ...          ...                 ...   \n",
      "95                 65            1                   1   \n",
      "96                 66            3                   0   \n",
      "97                 67            0                   1   \n",
      "98                 68            3                   1   \n",
      "99                 69            0                   1   \n",
      "\n",
      "    prior_question_elapsed_time  prior_question_had_explanation  lagged_time  \\\n",
      "0                         0.000                            <NA>        0.000   \n",
      "1                         0.028                           False       26.987   \n",
      "2                         0.024                           False       38.166   \n",
      "3                         0.035                           False       26.547   \n",
      "4                         0.021                           False      108.960   \n",
      "..                          ...                             ...          ...   \n",
      "95                        0.021                            True       69.577   \n",
      "96                        0.015                            True       75.497   \n",
      "97                        0.018                            True       92.179   \n",
      "98                        0.016                            True       68.817   \n",
      "99                        0.016                            True       74.349   \n",
      "\n",
      "    answered_correctly_user     sum  answered_correctly_content  \n",
      "0                  0.671915  1835.0                    0.838384  \n",
      "1                  0.671915  1835.0                    0.524239  \n",
      "2                  0.671915  1835.0                    0.413943  \n",
      "3                  0.671915  1835.0                    0.761983  \n",
      "4                  0.671915  1835.0                    0.701055  \n",
      "..                      ...     ...                         ...  \n",
      "95                 0.671915  1835.0                    0.818505  \n",
      "96                 0.671915  1835.0                    0.791878  \n",
      "97                 0.671915  1835.0                    0.832298  \n",
      "98                 0.671915  1835.0                    0.885914  \n",
      "99                 0.671915  1835.0                    0.548807  \n",
      "\n",
      "[100 rows x 14 columns]\n",
      "shape:  (2306848, 14)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def get_mappers(df_, cate_cols):\n",
    "\n",
    "    mappers_dict = {}\n",
    "    cate_offset = 1\n",
    "    for col in (cate_cols):    \n",
    "        cate2idx = {}\n",
    "        for v in df_[col].unique():\n",
    "            if (v != v) | (v == None): continue \n",
    "            cate2idx[v] = len(cate2idx)+cate_offset\n",
    "        mappers_dict[col] = cate2idx    \n",
    "        df_.loc[:,col] = df_[col].map(cate2idx).fillna(0).astype(int)\n",
    "        cate_offset += len(cate2idx)\n",
    "    return mappers_dict, cate_offset\n",
    "\n",
    "\n",
    "def summary_statistics(train):\n",
    "    results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "    results_c.columns = [\"answered_correctly_content\"]\n",
    "    results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\n",
    "    results_u.columns = [\"answered_correctly_user\", 'sum']\n",
    "#     results_c.to_pickle('results_c.pkl')\n",
    "#     results_u.to_pickle('results_u.pkl')\n",
    "    return results_c, results_u\n",
    "\n",
    "def agg_data(df_, mappers_dict, cate_cols = [], cont_cols = []):\n",
    "#     df_.loc[:, 'lagged_y'] = df_[['user_id', 'answered_correctly']].groupby('user_id')['answered_correctly'].shift(1)\n",
    "    df_.loc[:, 'lagged_time'] = df_[['user_id', 'timestamp']].groupby('user_id')['timestamp'].diff()/1e3\n",
    "\n",
    "    df_.loc[:, 'prior_question_elapsed_time'] = df_.loc[:, 'prior_question_elapsed_time']/1e6\n",
    "    results_c, results_u = summary_statistics(df_)\n",
    "    df_ = pd.merge(df_, results_u, on=['user_id'], how=\"left\")\n",
    "    df_ = pd.merge(df_, results_c, on=['content_id'], how=\"left\")\n",
    "    \n",
    "    \n",
    "    for col in (cate_cols):    \n",
    "        cate2idx = mappers_dict[col]\n",
    "        df_.loc[:,col] = df_[col].map(cate2idx).fillna(0).astype(int)\n",
    "        \n",
    "    for col in cont_cols:\n",
    "        df_[col].fillna(0, inplace=True)\n",
    "    return df_\n",
    "\n",
    "\n",
    "cate_cols = ['content_id']\n",
    "cont_cols = ['prior_question_elapsed_time','lagged_time',\"answered_correctly_content\", \"answered_correctly_user\"]\n",
    "print('shape: ', train_df_.shape)\n",
    "mappers_dict, cate_offset = get_mappers(train_df_, cate_cols)\n",
    "\n",
    "train_df = agg_data(train_df_, mappers_dict, cate_cols=cate_cols, cont_cols=cont_cols)\n",
    "print('head:', train_df.head(100))\n",
    "print('shape: ', train_df.shape)\n",
    "torch.save([train_samples, train_users, train_df, mappers_dict, cate_offset, cate_cols, cont_cols],\n",
    "           'ktracing_train_v0.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_id    timestamp    user_id  content_id  content_type_id  \\\n",
      "0  36988923    734303484  790098971        6940            False   \n",
      "1  27772579  22000097282  592529342        6566            False   \n",
      "2  20422501  16366712289  438327923       10742            False   \n",
      "3  14131213   8242160735  305936298       10032            False   \n",
      "4  41855831   7195910010  887942868        8447            False   \n",
      "\n",
      "   task_container_id  user_answer  answered_correctly  \\\n",
      "0                247            0                   0   \n",
      "1                797            0                   0   \n",
      "2               1416            0                   0   \n",
      "3               2199            0                   0   \n",
      "4                111            0                   0   \n",
      "\n",
      "   prior_question_elapsed_time  prior_question_had_explanation  \n",
      "0                       2250.0                            True  \n",
      "1                      61250.0                            True  \n",
      "2                      31250.0                            True  \n",
      "3                      13500.0                            True  \n",
      "4                       2000.0                            True  \n",
      "Wall time: 623 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import feather\n",
    "df = feather.read_dataframe('validation_v0.feather')\n",
    "df.shape\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_statistics(train):\n",
    "    results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "    results_c.columns = [\"answered_correctly_content\"]\n",
    "    results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\n",
    "    results_u.columns = [\"answered_correctly_user\", 'sum']\n",
    "    results_c.to_pickle('results_c.pkl')\n",
    "    results_u.to_pickle('results_u.pkl')\n",
    "    return results_c, results_u\n",
    "\n",
    "def encode_categorical(X,\n",
    "                       cols=None,\n",
    "                       categorical_vars=None,\n",
    "                       copy=True):\n",
    "    '''\n",
    "    Encode categorical variables as integers.\n",
    "\n",
    "    :param X: input DataFrame\n",
    "    :param categorical_vars: optional, list of categorical variables\n",
    "    :param copy: optional, whether to modify a copy\n",
    "    :return: DataFrame, LabelEncoders\n",
    "    '''\n",
    "    df = X.copy() if copy else X\n",
    "    encoders = {}\n",
    "\n",
    "    if not cols:\n",
    "        cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "    if categorical_vars is None:\n",
    "        categorical_vars = [col for col in df.columns if col in cols]\n",
    "\n",
    "    for var in categorical_vars:\n",
    "        encoders[var] = SafeLabelEncoder()\n",
    "        encoders[var].fit(df[var])\n",
    "        df.loc[:, var] = encoders[var].transform(df.loc[:, var])\n",
    "\n",
    "    return df, encoders\n",
    "\n",
    "class SafeLabelEncoder(LabelEncoder):\n",
    "    \"\"\"An extension of LabelEncoder that will\n",
    "    not throw an exception for unseen data, but will\n",
    "    instead return a default value of len(labels)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    classes_ : the classes that are encoded\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, y):\n",
    "\n",
    "        check_is_fitted(self, 'classes_')\n",
    "        y = column_or_1d(y, warn=True)\n",
    "\n",
    "        unseen = len(self.classes_)\n",
    "\n",
    "        e = np.array([\n",
    "                     np.searchsorted(self.classes_, x)\n",
    "                     if x in self.classes_ else unseen\n",
    "                     for x in y\n",
    "                     ])\n",
    "\n",
    "        if unseen in e:\n",
    "            self.classes_ = np.array(self.classes_.tolist() + ['unseen'])\n",
    "\n",
    "        return e\n",
    "    \n",
    "def get_embdded_df(data, target='answered_correctly', cols=['content_id']):\n",
    "    cat_vars = categorize(data, cols=cols)\n",
    "    embedding_dict = pick_emb_dim(cat_vars, max_dim=20)\n",
    "    data_x, data_y = data.drop([target],axis=1), data[target]\n",
    "    data_x_encoded, encoders = encode_categorical(data_x, cols=cols)\n",
    "    # embedding training\n",
    "    embedder = Embedder(embedding_dict, model_json=None)\n",
    "    embedder.fit(data_x_encoded[cols], data_y, epochs=1)\n",
    "    embeddings = embedder.get_embeddings()\n",
    "    return embeddings, encoders\n",
    "\n",
    "def add_embedding(data,encoders, embeddings):\n",
    "    return get_embed_df(data, encoders, embeddings)\n",
    "\n",
    "def get_train_data(df, target = 'answered_correctly'):\n",
    "    train = df[df.content_type_id == False]\n",
    "    results_c, results_u = summary_statistics(train)\n",
    "\n",
    "    train = pd.merge(train, results_u, on=['user_id'], how=\"left\")\n",
    "    train = pd.merge(train, results_c, on=['content_id'], how=\"left\")\n",
    "\n",
    "    X = train.drop([target], axis=1)\n",
    "    X['answered_correctly_user'].fillna(0.5,  inplace=True)\n",
    "    X['answered_correctly_content'].fillna(0.5,  inplace=True)\n",
    "    X.fillna(0, inplace = True)\n",
    "    Y = train[[\"answered_correctly\"]]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20939/20939 [==============================] - 100s 5ms/step - loss: 0.2008 - r2: 0.1208 - val_loss: 0.1871 - val_r2: -477081888.0000\n",
      "(13500, 20)\n",
      "(6834063, 10)\n",
      "(6700354, 31)\n",
      "['row_id', 'timestamp', 'user_id', 'content_type_id', 'task_container_id', 'user_answer', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'answered_correctly_user', 'sum', 'answered_correctly_content', 'embed_content_id0', 'embed_content_id1', 'embed_content_id2', 'embed_content_id3', 'embed_content_id4', 'embed_content_id5', 'embed_content_id6', 'embed_content_id7', 'embed_content_id8', 'embed_content_id9', 'embed_content_id10', 'embed_content_id11', 'embed_content_id12', 'embed_content_id13', 'embed_content_id14', 'embed_content_id15', 'embed_content_id16', 'embed_content_id17', 'embed_content_id18', 'embed_content_id19']\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X, Y = get_train_data(df)\n",
    "embeddings, encoders = get_embdded_df(df[df.content_type_id == False], cols=['content_id'])\n",
    "X_embedded = add_embedding(X,encoders, embeddings)\n",
    "\n",
    "print(embeddings['content_id'].shape)\n",
    "print(df.shape)\n",
    "print(X_embedded.shape)\n",
    "print(X_embedded.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\meipaopao\\pycharmprojects\\ktracing\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lgb_with_embed_v0.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features= [ 'answered_correctly_user', 'sum', 'answered_correctly_content'] +[col for col in X_embedded.columns if col.startswith('embed_')]\n",
    "\n",
    "param = {'num_leaves': 50, 'learning_rate': 0.1, 'subsample_for_bin': 130000, 'min_child_samples': 470, 'reg_alpha': 0.5, \n",
    "         'reg_lambda': 0.26, 'subsample': 0.5, 'is_unbalance': False, 'n_estimators': 1000, 'objective': 'binary', 'random_state': 126}\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier(**param)\n",
    "import numpy as np\n",
    "model.fit(X_embedded[features], Y)\n",
    "\n",
    "\n",
    "# save model\n",
    "joblib.dump(model, 'lgb_with_embed_v0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7941278924945345\n",
      "pred: 0.6741167078835231\n",
      "true: answered_correctly    0.667531\n",
      "dtype: float64\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with fs.open('ktracing/validation_v0-000000000001.csv') as f:\n",
    "    df_val = pd.read_csv(f, dtype=dtypes)\n",
    "X_val, Y_val = get_train_data(df_val)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_val_embedded = add_embedding(X_val,encoders, embeddings)\n",
    "\n",
    "\n",
    "features= [ 'answered_correctly_user', 'sum', 'answered_correctly_content'] + [col for col in X_val_embedded.columns if col.startswith('embed_')]\n",
    "\n",
    "\n",
    "Y_pred = model.predict_proba(X_val_embedded[features])[:, 1]\n",
    "\n",
    "print('score:', roc_auc_score(Y_val, Y_pred))\n",
    "print('pred:', Y_pred.mean())\n",
    "print('true:', Y_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# joblib.dump(model,open('lgb.pkl', 'wb') )\n",
    "pickle.dump(df_val,open('validation_v0.pkl', 'wb') )\n",
    "pickle.dump(encoders,open('encoders_content_id_v0.pkl', 'wb') )\n",
    "pickle.dump(embeddings,open('embeddings_content_id_v0.pkl', 'wb') )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
