{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"boolean\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"boolean\"\n",
    "}\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "import feather\n",
    "from embedder.regression import Embedder\n",
    "from embedder.preprocessing import (categorize,\n",
    "     pick_emb_dim,  get_embed_df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import column_or_1d\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(token=r\"C:\\Users\\meipaopao\\PycharmProjects\\ktracing_gcs.json\")\n",
    "\n",
    "def save_to_feather(file_name=\"validation-v0-00000000000\", output_file_name=\"validation_v0\", max_=30):\n",
    "    dataset = pd.DataFrame()\n",
    "    for i in range(max_):\n",
    "        file_path = f'gs://ktracing/{file_name}{i}.csv'\n",
    "        if not fs.exists(file_path):\n",
    "            break\n",
    "        with fs.open(file_path) as f:\n",
    "            print(i)\n",
    "            df = pd.read_csv(f, dtype=dtypes, index_col=False)\n",
    "            print('current shape:', df.shape)\n",
    "            dataset = pd.concat([dataset, df])\n",
    "            print('updated shape:', dataset.shape)\n",
    "    print('overall shape:', dataset.shape)\n",
    "    dataset.reset_index(drop=True).to_feather(f'{output_file_name}.feather')\n",
    "# gs://ktracing/train-v0-000000000000.csv\n",
    "# https://storage.cloud.google.com/ktracing/train_sample_000000000000.csv?authuser=1\n",
    "#save_to_feather(file_name=\"train-v0-00000000000\", output_file_name=\"train_v0\")\n",
    "#save_to_feather(file_name=\"train_sample_00000000000\", output_file_name=\"train_sample_v0\")\n",
    "# gs://ktracing/train_sample_v0_000000000000.csv\n",
    "#save_to_feather(file_name=\"train_sample_v0_00000000000\", output_file_name=\"train_sample_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "shape: (201205, 10)\n",
      "[1 0]\n",
      "size: 196786\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm as tqdm_notebook\n",
    "seq_len = 2\n",
    "# generate train sample indices\n",
    "def get_sample_indices(df_):\n",
    "    df = df_[df_.content_type_id==False]\n",
    "    print(df['answered_correctly'].unique())\n",
    "    sample_indices = []\n",
    "    user_indices = []\n",
    "    df_users = df.groupby('user_id').groups\n",
    "    for user_idx, start_indices in enumerate(df_users.values()):\n",
    "        #start_indices = one_df.index\n",
    "        #sample_indices.append(one_df.index.tolist())\n",
    "        #user_indices.append(user_idx)\n",
    "        assert df.iloc[start_indices]['answered_correctly'].nunique()<=2\n",
    "        for num, curr_index in enumerate(start_indices):\n",
    "            selected_index = start_indices[max(0,num-seq_len+1):num+1]\n",
    "            if selected_index[-1] != curr_index:\n",
    "                print('not matched!')\n",
    "\n",
    "            #print('y:', df[['answered_correctly']].iloc[curr_index[-1]].values)\n",
    "            sample_indices.append(selected_index)\n",
    "            user_indices.append(user_idx)\n",
    "#             uniques = df_[['answered_correctly']].iloc[curr_index]['answered_correctly'].unique()\n",
    "#             if len(uniques)>2:\n",
    "#                 print('unique: ', df_[['answered_correctly']].iloc[curr_index]['answered_correctly'].unique())\n",
    "    return sample_indices, user_indices\n",
    "\n",
    "# data load\n",
    "print('loading data')\n",
    "train_df = feather.read_dataframe('train_sample_v1.feather')\n",
    "print('shape:', train_df.shape)\n",
    "#test_df = feather.read_dataframe('validation_v0.feather')\n",
    "train_samples, train_users = get_sample_indices(train_df)\n",
    "\n",
    "print('size:', len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (201205, 10)\n",
      "   prior_question_elapsed_time  lagged_time\n",
      "0                      22000.0          NaN\n",
      "1                      17000.0          NaN\n",
      "2                      19000.0          NaN\n",
      "3                      26000.0          NaN\n",
      "4                      21000.0          NaN\n",
      "head:      row_id    timestamp    user_id  content_id  content_type_id  \\\n",
      "0  31408421    514367405  674040280          34            False   \n",
      "1  24623124   1566292394  526948179          34            False   \n",
      "2  28758973   1604921708  614907064          34            False   \n",
      "3   2260794    781984829   47975614          34            False   \n",
      "4  16864344  14449903373  362401676          34            False   \n",
      "\n",
      "   task_container_id  user_answer  answered_correctly  \\\n",
      "0                254            0                   1   \n",
      "1                 33            0                   1   \n",
      "2                487            0                   1   \n",
      "3                540            0                   1   \n",
      "4               6783            0                   1   \n",
      "\n",
      "   prior_question_elapsed_time  prior_question_had_explanation  lagged_time  \n",
      "0                      22000.0                            True          0.0  \n",
      "1                      17000.0                            True          0.0  \n",
      "2                      19000.0                            True          0.0  \n",
      "3                      26000.0                            True          0.0  \n",
      "4                      21000.0                            True          0.0  \n",
      "shape:  (201205, 11)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pd.options.mode.chained_assignment = None\n",
    "# ds = train_df['user_id'].value_counts().reset_index()\n",
    "# ds.columns = ['user_id', 'count']\n",
    "# ds = ds.sort_values(['count'])\n",
    "# print(ds['user_id'].values[-1])\n",
    "# df_ = train_df[train_df['user_id'] == 870330384]\n",
    "def get_mappers(df_, cate_cols):\n",
    "\n",
    "    mappers_dict = {}\n",
    "    cate_offset = 1\n",
    "    for col in (cate_cols):    \n",
    "        cate2idx = {}\n",
    "        for v in df_[col].unique():\n",
    "            if (v != v) | (v == None): continue \n",
    "            cate2idx[v] = len(cate2idx)+cate_offset\n",
    "        mappers_dict[col] = cate2idx    \n",
    "        df_.loc[:,col] = df_[col].map(cate2idx).fillna(0).astype(int)\n",
    "        cate_offset += len(cate2idx)\n",
    "    return mappers_dict, cate_offset\n",
    "\n",
    "def agg_data(df_, cate_cols, mappers_dict, cont_cols = ['prior_question_elapsed_time','lagged_time']):\n",
    "    df_.loc[:, 'lagged_time'] = df_[['user_id', 'timestamp']].groupby('user_id')['timestamp'].diff()\n",
    "    print(df_[['prior_question_elapsed_time','lagged_time']].head())\n",
    "\n",
    "    for col in (cate_cols):    \n",
    "        cate2idx = mappers_dict[col]\n",
    "        df_.loc[:,col] = df_[col].map(cate2idx).fillna(0).astype(int)\n",
    "        \n",
    "    for col in cont_cols:\n",
    "        df_.loc[:, col] = df_[col].fillna(0)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "\n",
    "cate_cols = ['content_id']\n",
    "cont_cols = ['prior_question_elapsed_time','lagged_time']\n",
    "print('shape: ', train_df.shape)\n",
    "mappers_dict, cate_offset = get_mappers(train_df, cate_cols)\n",
    "\n",
    "train_df = agg_data(train_df, cate_cols, mappers_dict)\n",
    "print('head:', train_df.head())\n",
    "print('shape: ', train_df.shape)\n",
    "torch.save([train_samples, train_users, train_df, mappers_dict, cate_offset, cate_cols, cont_cols],\n",
    "           'ktracing_train.pt')\n",
    "\n",
    "\n",
    "\n",
    "# cate_df = train_df[cate_cols]\n",
    "# indices = train_samples[0]\n",
    "# print('head:', cate_df.head())\n",
    "# print(cate_df.iloc[indices].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_id    timestamp    user_id  content_id  content_type_id  \\\n",
      "0  36988923    734303484  790098971        6940            False   \n",
      "1  27772579  22000097282  592529342        6566            False   \n",
      "2  20422501  16366712289  438327923       10742            False   \n",
      "3  14131213   8242160735  305936298       10032            False   \n",
      "4  41855831   7195910010  887942868        8447            False   \n",
      "\n",
      "   task_container_id  user_answer  answered_correctly  \\\n",
      "0                247            0                   0   \n",
      "1                797            0                   0   \n",
      "2               1416            0                   0   \n",
      "3               2199            0                   0   \n",
      "4                111            0                   0   \n",
      "\n",
      "   prior_question_elapsed_time  prior_question_had_explanation  \n",
      "0                       2250.0                            True  \n",
      "1                      61250.0                            True  \n",
      "2                      31250.0                            True  \n",
      "3                      13500.0                            True  \n",
      "4                       2000.0                            True  \n",
      "Wall time: 623 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import feather\n",
    "df = feather.read_dataframe('validation_v0.feather')\n",
    "df.shape\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_statistics(train):\n",
    "    results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "    results_c.columns = [\"answered_correctly_content\"]\n",
    "    results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\n",
    "    results_u.columns = [\"answered_correctly_user\", 'sum']\n",
    "    results_c.to_pickle('results_c.pkl')\n",
    "    results_u.to_pickle('results_u.pkl')\n",
    "    return results_c, results_u\n",
    "\n",
    "def encode_categorical(X,\n",
    "                       cols=None,\n",
    "                       categorical_vars=None,\n",
    "                       copy=True):\n",
    "    '''\n",
    "    Encode categorical variables as integers.\n",
    "\n",
    "    :param X: input DataFrame\n",
    "    :param categorical_vars: optional, list of categorical variables\n",
    "    :param copy: optional, whether to modify a copy\n",
    "    :return: DataFrame, LabelEncoders\n",
    "    '''\n",
    "    df = X.copy() if copy else X\n",
    "    encoders = {}\n",
    "\n",
    "    if not cols:\n",
    "        cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "    if categorical_vars is None:\n",
    "        categorical_vars = [col for col in df.columns if col in cols]\n",
    "\n",
    "    for var in categorical_vars:\n",
    "        encoders[var] = SafeLabelEncoder()\n",
    "        encoders[var].fit(df[var])\n",
    "        df.loc[:, var] = encoders[var].transform(df.loc[:, var])\n",
    "\n",
    "    return df, encoders\n",
    "\n",
    "class SafeLabelEncoder(LabelEncoder):\n",
    "    \"\"\"An extension of LabelEncoder that will\n",
    "    not throw an exception for unseen data, but will\n",
    "    instead return a default value of len(labels)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    classes_ : the classes that are encoded\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, y):\n",
    "\n",
    "        check_is_fitted(self, 'classes_')\n",
    "        y = column_or_1d(y, warn=True)\n",
    "\n",
    "        unseen = len(self.classes_)\n",
    "\n",
    "        e = np.array([\n",
    "                     np.searchsorted(self.classes_, x)\n",
    "                     if x in self.classes_ else unseen\n",
    "                     for x in y\n",
    "                     ])\n",
    "\n",
    "        if unseen in e:\n",
    "            self.classes_ = np.array(self.classes_.tolist() + ['unseen'])\n",
    "\n",
    "        return e\n",
    "    \n",
    "def get_embdded_df(data, target='answered_correctly', cols=['content_id']):\n",
    "    cat_vars = categorize(data, cols=cols)\n",
    "    embedding_dict = pick_emb_dim(cat_vars, max_dim=20)\n",
    "    data_x, data_y = data.drop([target],axis=1), data[target]\n",
    "    data_x_encoded, encoders = encode_categorical(data_x, cols=cols)\n",
    "    # embedding training\n",
    "    embedder = Embedder(embedding_dict, model_json=None)\n",
    "    embedder.fit(data_x_encoded[cols], data_y, epochs=1)\n",
    "    embeddings = embedder.get_embeddings()\n",
    "    return embeddings, encoders\n",
    "\n",
    "def add_embedding(data,encoders, embeddings):\n",
    "    return get_embed_df(data, encoders, embeddings)\n",
    "\n",
    "def get_train_data(df, target = 'answered_correctly'):\n",
    "    train = df[df.content_type_id == False]\n",
    "    results_c, results_u = summary_statistics(train)\n",
    "\n",
    "    train = pd.merge(train, results_u, on=['user_id'], how=\"left\")\n",
    "    train = pd.merge(train, results_c, on=['content_id'], how=\"left\")\n",
    "\n",
    "    X = train.drop([target], axis=1)\n",
    "    X['answered_correctly_user'].fillna(0.5,  inplace=True)\n",
    "    X['answered_correctly_content'].fillna(0.5,  inplace=True)\n",
    "    X.fillna(0, inplace = True)\n",
    "    Y = train[[\"answered_correctly\"]]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20939/20939 [==============================] - 100s 5ms/step - loss: 0.2008 - r2: 0.1208 - val_loss: 0.1871 - val_r2: -477081888.0000\n",
      "(13500, 20)\n",
      "(6834063, 10)\n",
      "(6700354, 31)\n",
      "['row_id', 'timestamp', 'user_id', 'content_type_id', 'task_container_id', 'user_answer', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'answered_correctly_user', 'sum', 'answered_correctly_content', 'embed_content_id0', 'embed_content_id1', 'embed_content_id2', 'embed_content_id3', 'embed_content_id4', 'embed_content_id5', 'embed_content_id6', 'embed_content_id7', 'embed_content_id8', 'embed_content_id9', 'embed_content_id10', 'embed_content_id11', 'embed_content_id12', 'embed_content_id13', 'embed_content_id14', 'embed_content_id15', 'embed_content_id16', 'embed_content_id17', 'embed_content_id18', 'embed_content_id19']\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X, Y = get_train_data(df)\n",
    "embeddings, encoders = get_embdded_df(df[df.content_type_id == False], cols=['content_id'])\n",
    "X_embedded = add_embedding(X,encoders, embeddings)\n",
    "\n",
    "print(embeddings['content_id'].shape)\n",
    "print(df.shape)\n",
    "print(X_embedded.shape)\n",
    "print(X_embedded.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\meipaopao\\pycharmprojects\\ktracing\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lgb_with_embed_v0.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features= [ 'answered_correctly_user', 'sum', 'answered_correctly_content'] +[col for col in X_embedded.columns if col.startswith('embed_')]\n",
    "\n",
    "param = {'num_leaves': 50, 'learning_rate': 0.1, 'subsample_for_bin': 130000, 'min_child_samples': 470, 'reg_alpha': 0.5, \n",
    "         'reg_lambda': 0.26, 'subsample': 0.5, 'is_unbalance': False, 'n_estimators': 1000, 'objective': 'binary', 'random_state': 126}\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier(**param)\n",
    "import numpy as np\n",
    "model.fit(X_embedded[features], Y)\n",
    "\n",
    "\n",
    "# save model\n",
    "joblib.dump(model, 'lgb_with_embed_v0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7941278924945345\n",
      "pred: 0.6741167078835231\n",
      "true: answered_correctly    0.667531\n",
      "dtype: float64\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with fs.open('ktracing/validation_v0-000000000001.csv') as f:\n",
    "    df_val = pd.read_csv(f, dtype=dtypes)\n",
    "X_val, Y_val = get_train_data(df_val)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_val_embedded = add_embedding(X_val,encoders, embeddings)\n",
    "\n",
    "\n",
    "features= [ 'answered_correctly_user', 'sum', 'answered_correctly_content'] + [col for col in X_val_embedded.columns if col.startswith('embed_')]\n",
    "\n",
    "\n",
    "Y_pred = model.predict_proba(X_val_embedded[features])[:, 1]\n",
    "\n",
    "print('score:', roc_auc_score(Y_val, Y_pred))\n",
    "print('pred:', Y_pred.mean())\n",
    "print('true:', Y_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# joblib.dump(model,open('lgb.pkl', 'wb') )\n",
    "pickle.dump(df_val,open('validation_v0.pkl', 'wb') )\n",
    "pickle.dump(encoders,open('encoders_content_id_v0.pkl', 'wb') )\n",
    "pickle.dump(embeddings,open('embeddings_content_id_v0.pkl', 'wb') )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
